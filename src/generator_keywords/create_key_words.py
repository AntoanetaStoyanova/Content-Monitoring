import json
from collections.abc import Iterable

import ollama
from beartype import beartype

from ..bin.log import logger
from ..bin.utils import clean_keywords

SYSTEM_PROMPT_TOPIC = (
    "Tu es un mod√®le NLP professionnel. "
    "R√©sume le sujet principal de la phrase suivante en 1 mot, "
    "comme le ferait un humain sur les r√©seaux sociaux. "
    "R√©pond STRICTEMENT avec le mot en minuscules, sans ponctuation."
)


def extract_main_topic(queries: Iterable[str], model: str) -> list[str]:
    """
    Extrait le sujet principal de chaque requ√™te en un seul mot.

    Cette fonction utilise un mod√®le NLP via Ollama pour r√©sumer
    chaque cat√©gorie ou phrase pass√©e dans `queries` en un seul mot
    repr√©sentatif, comme le ferait un humain sur les r√©seaux sociaux.
    La sortie est renvoy√©e sous forme de liste de mots en minuscules,
    dans le m√™me ordre que les requ√™tes fournies.

    :param queries: It√©rable de cha√Ænes de caract√®res repr√©sentant
                    les cat√©gories ou phrases √† analyser.
    :type queries: Iterable[str]

    :param model: Nom du mod√®le NLP √† utiliser pour l'extraction.
    :type model: str

    :return: Liste des sujets principaux extraits, un mot par requ√™te.
             Si une erreur survient ou le compte de sujets ne correspond
             pas, la liste originale est renvoy√©e en minuscules.
    :rtype: list[str]

    :raises Exception: Toute erreur de traitement ou d'acc√®s au mod√®le
                       est intercept√©e et logg√©e, mais ne bloque pas
                       la fonction (renvoie la liste originale).
    """
    # On transforme l'it√©rable en liste pour pouvoir compter
    query_list = list(queries)
    if not query_list:
        return []

    logger.info(
        f"‚ö° Extraction group√©e des sujets pour {len(query_list)} cat√©gories..."
    )

    # On pr√©pare une liste num√©rot√©e pour aider le mod√®le
    formatted_list = "\n".join([f"{i + 1}. {q}" for i, q in enumerate(query_list)])

    prompt = f"""
    Voici une liste de cat√©gories provenant de r√©seaux sociaux. 
    Pour chaque cat√©gorie, extrait le sujet principal en 1 seul mot (en minuscules).

    LISTE :
    {formatted_list}

    R√âPONDS STRICTEMENT AU FORMAT JSON SUIVANT :
    {{
        "topics": ["sujet1", "sujet2", "sujet3", ...]
    }}
    """

    try:
        response = ollama.chat(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            options={"temperature": 0},  # On veut de la pr√©cision, pas de cr√©ativit√©
        )

        content = response.get("message", {}).get("content", "").strip()

        # Nettoyage du JSON au cas o√π
        if "```" in content:
            content = content.split("```")[1].replace("json", "").strip()

        data = json.loads(content)
        topics = data.get("topics", [])

        # S√©curit√© : on v√©rifie que le compte est bon
        if len(topics) != len(query_list):
            logger.warning(
                f"‚ö†Ô∏è D√©calage : {len(topics)} sujets extraits pour {len(query_list)} requ√™tes."  # noqa: E501
            )
            # Si le compte n'est pas bon, on renvoie les queries originales par d√©faut
            return [q.lower() for q in query_list]

        return topics

    except Exception as e:
        logger.error(f"‚ùå Erreur extraction group√©e : {e}")
        # En cas d'√©chec, on retourne la liste originale en minuscules
        return [q.lower() for q in query_list]


@beartype
def generate_keywords(
    queries: list[str],
    model: str,
    n_keywords: int = 10,
) -> list[dict]:
    """
    G√©n√®re des mots-cl√©s uniques pour chaque requ√™te donn√©e.

    Cette fonction :
    1. Extrait le sujet principal de chaque requ√™te via `extract_main_topic`.
    2. Utilise un mod√®le NLP pour g√©n√©rer une liste de mots-cl√©s
       JSON respectant les contraintes (langues, format, nombre exact).
    3. Nettoie les r√©sultats via `clean_keywords` et logge les avertissements
       si le nombre de mots-cl√©s est insuffisant.
    4. Retourne une liste de dictionnaires contenant pour chaque requ√™te :
       - "query" : la requ√™te originale
       - "topic" : le sujet principal
       - "keywords" : la liste de mots-cl√©s valid√©s

    :param queries: Liste de cha√Ænes repr√©sentant les cat√©gories ou phrases √† traiter.
    :type queries: list[str]

    :param model: Nom du mod√®le NLP utilis√© pour g√©n√©rer les mots-cl√©s.
    :type model: str

    :param n_keywords: Nombre exact de mots-cl√©s √† g√©n√©rer par sujet.
    :type n_keywords: int

    :return: Liste de dictionnaires avec la structure :
             [{"query": str, "topic": str, "keywords": list[dict]}, ...]
    :rtype: list[dict]

    :raises Exception: Toute erreur lors de l'appel au mod√®le NLP ou
                       du traitement JSON est logg√©e, et le processus
                       continue pour les autres requ√™tes.
    """
    results: list[dict] = []
    main_topics = extract_main_topic(queries, model)

    for query, main_topic in zip(queries, main_topics, strict=False):
        if not main_topic:
            continue

        logger.info(f"üéØ Sujet principal : {main_topic} (Objectif: {n_keywords})")

        prompt = f"""
        G√©n√®re une liste JSON de EXACTEMENT {n_keywords} mots-cl√©s uniques pour le sujet "{main_topic}".

        Contraintes :
        - Format : [{{"keyword": "mot", "language": "fr"}}, {{"keyword": "word", "language": "en"}}]
        - Langues : un m√©lange de fran√ßais et d'anglais.
        - Uniquement du JSON, pas de texte avant ou apr√®s.
        - Ne t'arr√™te pas avant d'avoir atteint {n_keywords} √©l√©ments.
        """

        try:
            response = ollama.chat(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                options={
                    "num_predict": 4096,  # Permet une r√©ponse plus longue
                    "temperature": 0.8,  # Plus de diversit√© pour atteindre le nombre
                    "top_p": 0.9,
                },
            )

            content = response.get("message", {}).get("content", "").strip()

            # Nettoyage au cas o√π le mod√®le met des balises json
            if "```" in content:
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()

            parsed = json.loads(content)

            # Nettoyage via votre utilitaire
            clean_list = clean_keywords(parsed)

            if len(clean_list) < n_keywords:
                logger.warning(
                    f"‚ö†Ô∏è Manque de mots-cl√©s : {len(clean_list)}/{n_keywords} pour {main_topic}"
                )

            results.append(
                {
                    "query": query,
                    "topic": main_topic,
                    "keywords": clean_list,
                }
            )
            logger.info(f"‚úÖ {len(clean_list)} mots-cl√©s valid√©s pour {main_topic}")

        except json.JSONDecodeError:
            logger.error(
                f"‚ùå Erreur de format JSON pour {main_topic}. Contenu re√ßu : {content[:100]}..."
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration pour {main_topic} : {e}")

    return results
